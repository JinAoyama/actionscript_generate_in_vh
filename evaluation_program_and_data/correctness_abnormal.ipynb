{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_files = ['Fall_while_standing_and_turning1', 'Fall_while_preparing_meal1', 'Walk_with_memory_loss5', 'Fall_while_climbing_at_somewhere_height1', 'Fall_while_during_getting_up_or_rising1', 'Walk_with_memory_loss6', 'Fall_while_standing_at_somewhere_height1', 'Fall_while_preparing_meal2', 'Walk_with_memory_loss7', 'Fall_while_walking_forward1', 'Fall_while_standing_quietly1', 'Run_with_disorientation', 'Fall_sideways_while_walking_forward1', 'Fall_while_initiation_of_walking2', 'Walk_with_memory_loss8', 'Fall_while_sitting_down_or_lowering1', 'Fall_in_bathroom1', 'Fall_backward_while_walking_and_turning1', 'Stand_on_coffee_table1', 'Fall_while_standing_and_reaching1', 'Fall_while_sitting_down1', 'Fall_while_during_getting_up_or_rising2', 'Fall_while_initiation_of_walking1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_list(lst):\n",
    "    for i in range(0, len(lst)):\n",
    "        lst[i][0] = lst[i][0].replace(\"find\",\"walk\")\n",
    "\n",
    "    compressed_lst = []\n",
    "    for i in range(0, len(lst)):\n",
    "        if i == 0 or lst[i] != compressed_lst[-1] or \"walk\" not in lst[i]:\n",
    "            compressed_lst.append(lst[i])\n",
    "    return compressed_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.591\n",
      "recall: 0.481\n",
      "f1: 0.530\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"generated_kgrc_data/script_scene1.json\", \"r\") as json_file: #fill the path of the generated data file\n",
    "    result_scripts = json.load(json_file)\n",
    "\n",
    "with open(\"correct_kgrc_data/correct_scene1.json\", \"r\") as json_file: #fill the path of the correct data file\n",
    "    correct_data = json.load(json_file)\n",
    "\n",
    "precision_sum = 0\n",
    "recall_sum = 0\n",
    "abnormal_count = 0\n",
    "\n",
    "for f_num, correct in correct_data.items():\n",
    "    if f_num not in abnormal_files:\n",
    "\n",
    "        evaluation_data = result_scripts.get(f_num)\n",
    "    \n",
    "        for i, data in enumerate(evaluation_data):\n",
    "        \n",
    "            data = data.split()\n",
    "            new_data = [str(data[1])[1:-1]]\n",
    "\n",
    "            if len(data) == 4:\n",
    "                new_data.append(str(data[2])[1:-1]) \n",
    "            elif len(data) == 6:\n",
    "                new_data.append(str(data[2])[1:-1])\n",
    "                new_data.append(str(data[4])[1:-1])\n",
    "\n",
    "            evaluation_data[i] = new_data\n",
    "\n",
    "        evaluation_data = compress_list(evaluation_data)\n",
    "\n",
    "        for i, data in enumerate(correct):\n",
    "\n",
    "            data = data.split()\n",
    "            new_data = [str(data[0])[1:-1].lower()]\n",
    "\n",
    "            if len(data) == 3:\n",
    "                new_data.append(str(data[1])[1:-1]) \n",
    "            elif len(data) == 5:\n",
    "                new_data.append(str(data[1])[1:-1])\n",
    "                new_data.append(str(data[3])[1:-1])\n",
    "\n",
    "            correct[i] = new_data\n",
    "\n",
    "        correct = compress_list(correct)\n",
    "    \n",
    "        correct_len = len(correct)\n",
    "        evaluation_len = len(evaluation_data)\n",
    "\n",
    "        correct_num = 0\n",
    "        for e_data in evaluation_data:\n",
    "            for i, c_data in enumerate(correct):\n",
    "                if e_data[0] == c_data[0]:\n",
    "\n",
    "                    if len(e_data) == 1:\n",
    "                        correct_num += 1\n",
    "                        del correct[i]\n",
    "                        break\n",
    "\n",
    "                    elif len(e_data) == 2:\n",
    "                        if e_data[1] == c_data[1]:\n",
    "                            correct_num += 1\n",
    "                            del correct[i]\n",
    "                            break\n",
    "\n",
    "                    else:\n",
    "                        if e_data[1] == c_data[1] and e_data[2] == c_data[2]:\n",
    "                            correct_num += 1\n",
    "                            del correct[i]\n",
    "                            break\n",
    "    \n",
    "        if evaluation_len == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = correct_num/evaluation_len\n",
    "    \n",
    "        if correct_len == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = correct_num/correct_len\n",
    "\n",
    "        precision_sum += precision\n",
    "        recall_sum += recall\n",
    "\n",
    "    else:\n",
    "        abnormal_count += 1\n",
    "\n",
    "num = len(correct_data)-abnormal_count\n",
    "\n",
    "print(\"precision: {:.3f}\".format(precision_sum/num))\n",
    "print(\"recall: {:.3f}\".format(recall_sum/num))      \n",
    "print(\"f1: {:.3f}\".format(2*(precision_sum/num)*(recall_sum/num)/((precision_sum/num)+(recall_sum/num))) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VH",
   "language": "python",
   "name": "vh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
