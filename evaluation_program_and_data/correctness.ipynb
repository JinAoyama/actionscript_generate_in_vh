{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_list(lst):\n",
    "    for i in range(0, len(lst)):\n",
    "        lst[i][0] = lst[i][0].replace(\"find\",\"walk\")\n",
    "\n",
    "    compressed_lst = []\n",
    "    for i in range(0, len(lst)):\n",
    "        if i == 0 or lst[i] != compressed_lst[-1] or \"walk\" not in lst[i]:\n",
    "            compressed_lst.append(lst[i])\n",
    "    return compressed_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VH dataset (class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene 1: \n",
      "precision: 0.740\n",
      "recall: 0.581\n",
      "f1: 0.651\n",
      "\n",
      "Scene 2: \n",
      "precision: 0.703\n",
      "recall: 0.548\n",
      "f1: 0.616\n",
      "\n",
      "Scene 3: \n",
      "precision: 0.726\n",
      "recall: 0.531\n",
      "f1: 0.613\n",
      "\n",
      "Scene 4: \n",
      "precision: 0.689\n",
      "recall: 0.491\n",
      "f1: 0.573\n",
      "\n",
      "Scene 5: \n",
      "precision: 0.678\n",
      "recall: 0.516\n",
      "f1: 0.586\n",
      "\n",
      "Scene 6: \n",
      "precision: 0.732\n",
      "recall: 0.551\n",
      "f1: 0.629\n",
      "\n",
      "Scene 7: \n",
      "precision: 0.682\n",
      "recall: 0.549\n",
      "f1: 0.608\n",
      "\n",
      "Mean: \n",
      "presision: 0.707\n",
      "recall: 0.538\n",
      "f1: 0.611\n"
     ]
    }
   ],
   "source": [
    "precision_mean = []\n",
    "recall_mean = []\n",
    "f1_mean = []\n",
    "\n",
    "for scene_num in range(1, 8):\n",
    "\n",
    "    with open(f\"generated_vh_data/Class_name/class_name_script_scene{scene_num}.json\", \"r\") as json_file: #fill the path of the generated data file\n",
    "        result_scripts = json.load(json_file)\n",
    "\n",
    "    with open(f\"correct_vh_data/correct_scene{scene_num}.json\", \"r\") as json_file: #fill the path of the correct data file\n",
    "        correct_data = json.load(json_file)\n",
    "\n",
    "    precision_sum = 0\n",
    "    recall_sum = 0\n",
    "\n",
    "    for f_num, correct in correct_data.items():\n",
    "\n",
    "        evaluation_data = result_scripts.get(f_num)\n",
    "    \n",
    "        for i, data in enumerate(evaluation_data):\n",
    "        \n",
    "            data = data.split()\n",
    "            new_data = [str(data[1])[1:-1].lower()]\n",
    "\n",
    "            if len(data) == 4:\n",
    "                new_data.append(str(data[2])[1:-1]) \n",
    "            elif len(data) == 6:\n",
    "                new_data.append(str(data[2])[1:-1])\n",
    "                new_data.append(str(data[4])[1:-1])\n",
    "\n",
    "            evaluation_data[i] = new_data\n",
    "\n",
    "        evaluation_data = compress_list(evaluation_data)\n",
    "\n",
    "        for i, data in enumerate(correct):\n",
    "\n",
    "            data = data.split()\n",
    "            new_data = [str(data[0])[1:-1].lower()]\n",
    "\n",
    "            if len(data) == 3:\n",
    "                new_data.append(str(data[1])[1:-1]) \n",
    "            elif len(data) == 5:\n",
    "                new_data.append(str(data[1])[1:-1])\n",
    "                new_data.append(str(data[3])[1:-1])\n",
    "\n",
    "            correct[i] = new_data\n",
    "\n",
    "        correct = compress_list(correct)\n",
    "    \n",
    "        correct_len = len(correct)\n",
    "        evaluation_len = len(evaluation_data)\n",
    "\n",
    "        correct_num = 0\n",
    "        for e_data in evaluation_data:\n",
    "            for i, c_data in enumerate(correct):\n",
    "                if e_data[0] == c_data[0]:\n",
    "\n",
    "                    if len(e_data) == 1:\n",
    "                        correct_num += 1\n",
    "                        del correct[i]\n",
    "                        break\n",
    "\n",
    "                    elif len(e_data) == 2:\n",
    "                        if e_data[1] == c_data[1]:\n",
    "                            correct_num += 1\n",
    "                            del correct[i]\n",
    "                            break\n",
    "\n",
    "                    else:\n",
    "                        if e_data[1] == c_data[1] and e_data[2] == c_data[2]:\n",
    "                            correct_num += 1\n",
    "                            del correct[i]\n",
    "                            break\n",
    "    \n",
    "        if evaluation_len == 0:\n",
    "                precision = 0\n",
    "        else:\n",
    "            precision = correct_num/evaluation_len\n",
    "    \n",
    "        if correct_len == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = correct_num/correct_len\n",
    "\n",
    "        precision_sum += precision\n",
    "        recall_sum += recall\n",
    "\n",
    "    print(f\"Scene {scene_num}: \")\n",
    "    print(\"precision: {:.3f}\".format(precision_sum/len(correct_data)))\n",
    "    print(\"recall: {:.3f}\".format(recall_sum/len(correct_data)))      \n",
    "    print(\"f1: {:.3f}\".format(2*(precision_sum/len(correct_data))*(recall_sum/len(correct_data))/((precision_sum/len(correct_data))+(recall_sum/len(correct_data)))) )\n",
    "    print()\n",
    "\n",
    "    precision_mean.append(precision_sum/len(correct_data))\n",
    "    recall_mean.append(recall_sum/len(correct_data))\n",
    "    f1_mean.append(2*(precision_sum/len(correct_data))*(recall_sum/len(correct_data))/((precision_sum/len(correct_data))+(recall_sum/len(correct_data))))\n",
    "\n",
    "print(\"Mean: \")\n",
    "print(\"presision: {:.3f}\".format(numpy.mean(precision_mean)))\n",
    "print(\"recall: {:.3f}\".format(numpy.mean(recall_mean)))\n",
    "print(\"f1: {:.3f}\".format(numpy.mean(f1_mean)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VH dataset (object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene 1: \n",
      "precision: 0.157\n",
      "recall: 0.131\n",
      "f1: 0.143\n",
      "\n",
      "Scene 2: \n",
      "precision: 0.161\n",
      "recall: 0.124\n",
      "f1: 0.140\n",
      "\n",
      "Scene 3: \n",
      "precision: 0.140\n",
      "recall: 0.103\n",
      "f1: 0.119\n",
      "\n",
      "Scene 4: \n",
      "precision: 0.215\n",
      "recall: 0.155\n",
      "f1: 0.180\n",
      "\n",
      "Scene 5: \n",
      "precision: 0.127\n",
      "recall: 0.100\n",
      "f1: 0.112\n",
      "\n",
      "Scene 6: \n",
      "precision: 0.178\n",
      "recall: 0.135\n",
      "f1: 0.154\n",
      "\n",
      "Scene 7: \n",
      "precision: 0.197\n",
      "recall: 0.154\n",
      "f1: 0.173\n",
      "\n",
      "Mean: \n",
      "presision: 0.168\n",
      "recall: 0.129\n",
      "f1: 0.146\n"
     ]
    }
   ],
   "source": [
    "precision_mean = []\n",
    "recall_mean = []\n",
    "f1_mean = []\n",
    "\n",
    "for scene_num in range(1, 8):\n",
    "\n",
    "    with open(f\"generated_vh_data/Object_name/object_name_script_scene{scene_num}.json\", \"r\") as json_file: #fill the path of the generated data file\n",
    "        result_scripts = json.load(json_file)\n",
    "\n",
    "    with open(f\"correct_vh_data/correct_scene{scene_num}.json\", \"r\") as json_file: #fill the path of the correct data file\n",
    "        correct_data = json.load(json_file)\n",
    "\n",
    "    precision_sum = 0\n",
    "    recall_sum = 0\n",
    "\n",
    "    for f_num, correct in correct_data.items():\n",
    "\n",
    "        evaluation_data = result_scripts.get(f_num)\n",
    "    \n",
    "        for i, data in enumerate(evaluation_data):\n",
    "        \n",
    "            data = data.split()\n",
    "            new_data = [str(data[1])[1:-1].lower()]\n",
    "\n",
    "            if len(data) == 4:\n",
    "                new_data.append(str(data[2])[1:-1]) \n",
    "            elif len(data) == 6:\n",
    "                new_data.append(str(data[2])[1:-1])\n",
    "                new_data.append(str(data[4])[1:-1])\n",
    "\n",
    "            evaluation_data[i] = new_data\n",
    "\n",
    "        evaluation_data = compress_list(evaluation_data)\n",
    "\n",
    "        for i, data in enumerate(correct):\n",
    "\n",
    "            data = data.split()\n",
    "            new_data = [str(data[0])[1:-1].lower()]\n",
    "\n",
    "            if len(data) == 3:\n",
    "                new_data.append(str(data[1])[1:-1]) \n",
    "            elif len(data) == 5:\n",
    "                new_data.append(str(data[1])[1:-1])\n",
    "                new_data.append(str(data[3])[1:-1])\n",
    "\n",
    "            correct[i] = new_data\n",
    "\n",
    "        correct = compress_list(correct)\n",
    "    \n",
    "        correct_len = len(correct)\n",
    "        evaluation_len = len(evaluation_data)\n",
    "\n",
    "        correct_num = 0\n",
    "        for e_data in evaluation_data:\n",
    "            for i, c_data in enumerate(correct):\n",
    "                if e_data[0] == c_data[0]:\n",
    "\n",
    "                    if len(e_data) == 1:\n",
    "                        correct_num += 1\n",
    "                        del correct[i]\n",
    "                        break\n",
    "\n",
    "                    elif len(e_data) == 2:\n",
    "                        if e_data[1] == c_data[1]:\n",
    "                            correct_num += 1\n",
    "                            del correct[i]\n",
    "                            break\n",
    "\n",
    "                    else:\n",
    "                        if e_data[1] == c_data[1] and e_data[2] == c_data[2]:\n",
    "                            correct_num += 1\n",
    "                            del correct[i]\n",
    "                            break\n",
    "    \n",
    "        if evaluation_len == 0:\n",
    "                precision = 0\n",
    "        else:\n",
    "            precision = correct_num/evaluation_len\n",
    "    \n",
    "        if correct_len == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = correct_num/correct_len\n",
    "\n",
    "        precision_sum += precision\n",
    "        recall_sum += recall\n",
    "\n",
    "    print(f\"Scene {scene_num}: \")\n",
    "    print(\"precision: {:.3f}\".format(precision_sum/len(correct_data)))\n",
    "    print(\"recall: {:.3f}\".format(recall_sum/len(correct_data)))      \n",
    "    print(\"f1: {:.3f}\".format(2*(precision_sum/len(correct_data))*(recall_sum/len(correct_data))/((precision_sum/len(correct_data))+(recall_sum/len(correct_data)))) )\n",
    "    print()\n",
    "\n",
    "    precision_mean.append(precision_sum/len(correct_data))\n",
    "    recall_mean.append(recall_sum/len(correct_data))\n",
    "    f1_mean.append(2*(precision_sum/len(correct_data))*(recall_sum/len(correct_data))/((precision_sum/len(correct_data))+(recall_sum/len(correct_data))))\n",
    "\n",
    "print(\"Mean: \")\n",
    "print(\"presision: {:.3f}\".format(numpy.mean(precision_mean)))\n",
    "print(\"recall: {:.3f}\".format(numpy.mean(recall_mean)))\n",
    "print(\"f1: {:.3f}\".format(numpy.mean(f1_mean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KGRC4SI dataset (with Abnormal category data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene 1: \n",
      "precision: 0.570\n",
      "recall: 0.469\n",
      "f1: 0.514\n",
      "\n",
      "Scene 2: \n",
      "precision: 0.607\n",
      "recall: 0.538\n",
      "f1: 0.570\n",
      "\n",
      "Scene 3: \n",
      "precision: 0.539\n",
      "recall: 0.452\n",
      "f1: 0.492\n",
      "\n",
      "Scene 4: \n",
      "precision: 0.649\n",
      "recall: 0.494\n",
      "f1: 0.561\n",
      "\n",
      "Scene 5: \n",
      "precision: 0.548\n",
      "recall: 0.443\n",
      "f1: 0.490\n",
      "\n",
      "Scene 6: \n",
      "precision: 0.548\n",
      "recall: 0.449\n",
      "f1: 0.494\n",
      "\n",
      "Scene 7: \n",
      "precision: 0.652\n",
      "recall: 0.518\n",
      "f1: 0.577\n",
      "\n",
      "Mean: \n",
      "presision: 0.588\n",
      "recall: 0.480\n",
      "f1: 0.528\n"
     ]
    }
   ],
   "source": [
    "precision_mean = []\n",
    "recall_mean = []\n",
    "f1_mean = []\n",
    "\n",
    "for scene_num in range(1, 8):\n",
    "\n",
    "    with open(f\"generated_kgrc_data/script_scene{scene_num}.json\", \"r\") as json_file: #fill the path of the generated data file\n",
    "        result_scripts = json.load(json_file)\n",
    "\n",
    "    with open(f\"correct_kgrc_data/correct_scene{scene_num}.json\", \"r\") as json_file: #fill the path of the correct data file\n",
    "        correct_data = json.load(json_file)\n",
    "\n",
    "    precision_sum = 0\n",
    "    recall_sum = 0\n",
    "\n",
    "    for f_num, correct in correct_data.items():\n",
    "\n",
    "        evaluation_data = result_scripts.get(f_num)\n",
    "    \n",
    "        for i, data in enumerate(evaluation_data):\n",
    "        \n",
    "            data = data.split()\n",
    "            new_data = [str(data[1])[1:-1].lower()]\n",
    "\n",
    "            if len(data) == 4:\n",
    "                new_data.append(str(data[2])[1:-1]) \n",
    "            elif len(data) == 6:\n",
    "                new_data.append(str(data[2])[1:-1])\n",
    "                new_data.append(str(data[4])[1:-1])\n",
    "\n",
    "            evaluation_data[i] = new_data\n",
    "\n",
    "        evaluation_data = compress_list(evaluation_data)\n",
    "\n",
    "        for i, data in enumerate(correct):\n",
    "\n",
    "            data = data.split()\n",
    "            new_data = [str(data[0])[1:-1].lower()]\n",
    "\n",
    "            if len(data) == 3:\n",
    "                new_data.append(str(data[1])[1:-1]) \n",
    "            elif len(data) == 5:\n",
    "                new_data.append(str(data[1])[1:-1])\n",
    "                new_data.append(str(data[3])[1:-1])\n",
    "\n",
    "            correct[i] = new_data\n",
    "\n",
    "        correct = compress_list(correct)\n",
    "    \n",
    "        correct_len = len(correct)\n",
    "        evaluation_len = len(evaluation_data)\n",
    "\n",
    "        correct_num = 0\n",
    "        for e_data in evaluation_data:\n",
    "            for i, c_data in enumerate(correct):\n",
    "                if e_data[0] == c_data[0]:\n",
    "\n",
    "                    if len(e_data) == 1:\n",
    "                        correct_num += 1\n",
    "                        del correct[i]\n",
    "                        break\n",
    "\n",
    "                    elif len(e_data) == 2:\n",
    "                        if e_data[1] == c_data[1]:\n",
    "                            correct_num += 1\n",
    "                            del correct[i]\n",
    "                            break\n",
    "\n",
    "                    else:\n",
    "                        if e_data[1] == c_data[1] and e_data[2] == c_data[2]:\n",
    "                            correct_num += 1\n",
    "                            del correct[i]\n",
    "                            break\n",
    "    \n",
    "        if evaluation_len == 0:\n",
    "                precision = 0\n",
    "        else:\n",
    "            precision = correct_num/evaluation_len\n",
    "    \n",
    "        if correct_len == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = correct_num/correct_len\n",
    "\n",
    "        precision_sum += precision\n",
    "        recall_sum += recall\n",
    "\n",
    "    print(f\"Scene {scene_num}: \")\n",
    "    print(\"precision: {:.3f}\".format(precision_sum/len(correct_data)))\n",
    "    print(\"recall: {:.3f}\".format(recall_sum/len(correct_data)))      \n",
    "    print(\"f1: {:.3f}\".format(2*(precision_sum/len(correct_data))*(recall_sum/len(correct_data))/((precision_sum/len(correct_data))+(recall_sum/len(correct_data)))) )\n",
    "    print()\n",
    "\n",
    "    precision_mean.append(precision_sum/len(correct_data))\n",
    "    recall_mean.append(recall_sum/len(correct_data))\n",
    "    f1_mean.append(2*(precision_sum/len(correct_data))*(recall_sum/len(correct_data))/((precision_sum/len(correct_data))+(recall_sum/len(correct_data))))\n",
    "\n",
    "print(\"Mean: \")\n",
    "print(\"presision: {:.3f}\".format(numpy.mean(precision_mean)))\n",
    "print(\"recall: {:.3f}\".format(numpy.mean(recall_mean)))\n",
    "print(\"f1: {:.3f}\".format(numpy.mean(f1_mean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KGRC4SI dataset (without Abnormal category data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abnormal_files = ['Fall_while_standing_and_turning1', 'Fall_while_preparing_meal1', 'Walk_with_memory_loss5', 'Fall_while_climbing_at_somewhere_height1', 'Fall_while_during_getting_up_or_rising1', 'Walk_with_memory_loss6', 'Fall_while_standing_at_somewhere_height1', 'Fall_while_preparing_meal2', 'Walk_with_memory_loss7', 'Fall_while_walking_forward1', 'Fall_while_standing_quietly1', 'Run_with_disorientation', 'Fall_sideways_while_walking_forward1', 'Fall_while_initiation_of_walking2', 'Walk_with_memory_loss8', 'Fall_while_sitting_down_or_lowering1', 'Fall_in_bathroom1', 'Fall_backward_while_walking_and_turning1', 'Stand_on_coffee_table1', 'Fall_while_standing_and_reaching1', 'Fall_while_sitting_down1', 'Fall_while_during_getting_up_or_rising2', 'Fall_while_initiation_of_walking1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene 1: \n",
      "precision: 0.591\n",
      "recall: 0.481\n",
      "f1: 0.530\n",
      "\n",
      "Scene 2: \n",
      "precision: 0.634\n",
      "recall: 0.563\n",
      "f1: 0.596\n",
      "\n",
      "Scene 3: \n",
      "precision: 0.551\n",
      "recall: 0.468\n",
      "f1: 0.506\n",
      "\n",
      "Scene 4: \n",
      "precision: 0.680\n",
      "recall: 0.499\n",
      "f1: 0.575\n",
      "\n",
      "Scene 5: \n",
      "precision: 0.563\n",
      "recall: 0.462\n",
      "f1: 0.507\n",
      "\n",
      "Scene 6: \n",
      "precision: 0.568\n",
      "recall: 0.472\n",
      "f1: 0.515\n",
      "\n",
      "Scene 7: \n",
      "precision: 0.671\n",
      "recall: 0.541\n",
      "f1: 0.599\n",
      "\n",
      "Mean: \n",
      "presision: 0.608\n",
      "recall: 0.498\n",
      "f1: 0.547\n"
     ]
    }
   ],
   "source": [
    "precision_mean = []\n",
    "recall_mean = []\n",
    "f1_mean = []\n",
    "\n",
    "for scene_num in range(1, 8):\n",
    "\n",
    "    with open(f\"generated_kgrc_data/script_scene{scene_num}.json\", \"r\") as json_file: #fill the path of the generated data file\n",
    "        result_scripts = json.load(json_file)\n",
    "\n",
    "    with open(f\"correct_kgrc_data/correct_scene{scene_num}.json\", \"r\") as json_file: #fill the path of the correct data file\n",
    "        correct_data = json.load(json_file)\n",
    "\n",
    "    precision_sum = 0\n",
    "    recall_sum = 0\n",
    "    abnormal_count = 0\n",
    "\n",
    "    for f_num, correct in correct_data.items():\n",
    "        if f_num not in abnormal_files:\n",
    "\n",
    "            evaluation_data = result_scripts.get(f_num)\n",
    "    \n",
    "            for i, data in enumerate(evaluation_data):\n",
    "        \n",
    "                data = data.split()\n",
    "                new_data = [str(data[1])[1:-1]]\n",
    "\n",
    "                if len(data) == 4:\n",
    "                    new_data.append(str(data[2])[1:-1]) \n",
    "                elif len(data) == 6:\n",
    "                    new_data.append(str(data[2])[1:-1])\n",
    "                    new_data.append(str(data[4])[1:-1])\n",
    "\n",
    "                evaluation_data[i] = new_data\n",
    "\n",
    "            evaluation_data = compress_list(evaluation_data)\n",
    "\n",
    "            for i, data in enumerate(correct):\n",
    "\n",
    "                data = data.split()\n",
    "                new_data = [str(data[0])[1:-1].lower()]\n",
    "\n",
    "                if len(data) == 3:\n",
    "                    new_data.append(str(data[1])[1:-1]) \n",
    "                elif len(data) == 5:\n",
    "                    new_data.append(str(data[1])[1:-1])\n",
    "                    new_data.append(str(data[3])[1:-1])\n",
    "\n",
    "                correct[i] = new_data\n",
    "\n",
    "            correct = compress_list(correct)\n",
    "    \n",
    "            correct_len = len(correct)\n",
    "            evaluation_len = len(evaluation_data)\n",
    "\n",
    "            correct_num = 0\n",
    "            for e_data in evaluation_data:\n",
    "                for i, c_data in enumerate(correct):\n",
    "                    if e_data[0] == c_data[0]:\n",
    "\n",
    "                        if len(e_data) == 1:\n",
    "                            correct_num += 1\n",
    "                            del correct[i]\n",
    "                            break\n",
    "\n",
    "                        elif len(e_data) == 2:\n",
    "                            if e_data[1] == c_data[1]:\n",
    "                                correct_num += 1\n",
    "                                del correct[i]\n",
    "                                break\n",
    "\n",
    "                        else:\n",
    "                            if e_data[1] == c_data[1] and e_data[2] == c_data[2]:\n",
    "                                correct_num += 1\n",
    "                                del correct[i]\n",
    "                                break\n",
    "    \n",
    "            if evaluation_len == 0:\n",
    "                precision = 0\n",
    "            else:\n",
    "                precision = correct_num/evaluation_len\n",
    "    \n",
    "            if correct_len == 0:\n",
    "                recall = 0\n",
    "            else:\n",
    "                recall = correct_num/correct_len\n",
    "\n",
    "            precision_sum += precision\n",
    "            recall_sum += recall\n",
    "\n",
    "        else:\n",
    "            abnormal_count += 1\n",
    "\n",
    "    num = len(correct_data)-abnormal_count\n",
    "\n",
    "    \n",
    "    print(f\"Scene {scene_num}: \")\n",
    "    print(\"precision: {:.3f}\".format(precision_sum/num))\n",
    "    print(\"recall: {:.3f}\".format(recall_sum/num))      \n",
    "    print(\"f1: {:.3f}\".format(2*(precision_sum/num)*(recall_sum/num)/((precision_sum/num)+(recall_sum/num))) )\n",
    "    print()\n",
    "\n",
    "    precision_mean.append(precision_sum/num)\n",
    "    recall_mean.append(recall_sum/num)\n",
    "    f1_mean.append(2*(precision_sum/num)*(recall_sum/num)/((precision_sum/num)+(recall_sum/num)))\n",
    "\n",
    "print(\"Mean: \")\n",
    "print(\"presision: {:.3f}\".format(numpy.mean(precision_mean)))\n",
    "print(\"recall: {:.3f}\".format(numpy.mean(recall_mean)))\n",
    "print(\"f1: {:.3f}\".format(numpy.mean(f1_mean)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
